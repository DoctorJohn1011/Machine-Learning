{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tnensorflow 5 例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creat data\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data*0.1 + 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.62215161] [ 0.0308352]\n",
      "20 [ 0.23239382] [ 0.23099613]\n",
      "40 [ 0.13364778] [ 0.28246272]\n",
      "60 [ 0.10855156] [ 0.29554293]\n",
      "80 [ 0.1021734] [ 0.29886723]\n",
      "100 [ 0.10055237] [ 0.29971212]\n",
      "120 [ 0.10014039] [ 0.29992685]\n",
      "140 [ 0.10003569] [ 0.29998142]\n",
      "160 [ 0.10000908] [ 0.29999527]\n",
      "180 [ 0.10000231] [ 0.29999882]\n",
      "200 [ 0.1000006] [ 0.29999971]\n"
     ]
    }
   ],
   "source": [
    "### creat tensorflow structure start ###\n",
    "Weights = tf.Variable( tf.random_uniform([1],-1.0,1.0) )\n",
    "biases = tf.Variable( tf.zeros([1]) )\n",
    "\n",
    "y = Weights*x_data + biases\n",
    "\n",
    "loss = tf.reduce_mean( tf.square(y-y_data) )\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "### creat tensorflow structure start ###\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print( step, sess.run(Weights), sess.run(biases) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 6 Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3,3]])\n",
    "matrix2 = tf.constant([[2],[2]])\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2)    # matrix multiply np.dot(m1,m2)\n",
    "\n",
    "# method 1\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "# method 2\n",
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 7 Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter:0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "state = tf.Variable(0, name='counter')\n",
    "print(state.name)\n",
    "one = tf.constant(1)\n",
    "\n",
    "new_value = tf.add(state , one)\n",
    "update = tf.assign(state , new_value)\n",
    "\n",
    "init = tf.global_variables_initializer()  # must have if define variable\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 8 Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.   8.   4.]]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32, shape = (1,3))\n",
    "\n",
    "output = tf.multiply(input1 , input2)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict = {input1:[2.],input2:[[7.,4.,2.]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 10 def add_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def add_layer(inputs, in_size, out_size, activation_funtion=None):\n",
    "        Weights = tf.Variable( tf.random_normal( [in_size,out_size] ) )\n",
    "        biases = tf.Variable( tf.zeros( [1,out_size] ) + 0.1 )\n",
    "        Wx_plus_b = tf.matmul( inputs,Weights ) + biases\n",
    "        if activation_funtion is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_funtion( Wx_plus_b )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 11 build a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def add_layer(inputs, in_size, out_size, activation_funtion=None):\n",
    "        Weights = tf.Variable( tf.random_normal( [in_size,out_size] ) )\n",
    "        biases = tf.Variable( tf.zeros( [1,out_size] ) + 0.1 )\n",
    "        Wx_plus_b = tf.matmul( inputs,Weights ) + biases\n",
    "        if activation_funtion is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_funtion( Wx_plus_b )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.linspace( -1,1,300 )[:,np.newaxis]\n",
    "noise = np.random.normal( 0,0.05,x_data.shape )\n",
    "y_data = np.square( x_data ) - 0.5 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.461601\n",
      "0.0120344\n",
      "0.00790422\n",
      "0.00604386\n",
      "0.0050218\n",
      "0.00450687\n",
      "0.00421083\n",
      "0.00398839\n",
      "0.00381866\n",
      "0.00365744\n",
      "0.00352286\n",
      "0.00343137\n",
      "0.00335766\n",
      "0.00329151\n",
      "0.00323591\n",
      "0.00319109\n",
      "0.00315392\n",
      "0.00312234\n",
      "0.00309026\n",
      "0.00305456\n"
     ]
    }
   ],
   "source": [
    "xs = tf.placeholder( tf.float32,[None,1] )\n",
    "ys = tf.placeholder( tf.float32,[None,1] )\n",
    "\n",
    "l1 = add_layer( xs,1,10,activation_funtion=tf.nn.relu )\n",
    "prediction = add_layer( l1,10,1 )\n",
    "\n",
    "loss = tf.reduce_mean( tf.reduce_sum( tf.square( ys - prediction ),reduction_indices=[1] ) )\n",
    "train_step = tf.train.GradientDescentOptimizer( 0.1 ).minimize( loss )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run( init )\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run( train_step,feed_dict={xs:x_data,ys:y_data})\n",
    "    if i % 50 == 0:\n",
    "        print(sess.run( loss,feed_dict={xs:x_data,ys:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 12 plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_funtion=None):\n",
    "        Weights = tf.Variable( tf.random_normal( [in_size,out_size] ) )\n",
    "        biases = tf.Variable( tf.zeros( [1,out_size] ) + 0.1 )\n",
    "        Wx_plus_b = tf.matmul( inputs,Weights ) + biases\n",
    "        if activation_funtion is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_funtion( Wx_plus_b )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.linspace( -1,1,300 )[:,np.newaxis]\n",
    "noise = np.random.normal( 0,0.05,x_data.shape )\n",
    "y_data = np.square( x_data ) - 0.5 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCillHKhgUEppZQLDQxKKaVc/D/C3u+r7F96igAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc7fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = tf.placeholder( tf.float32,[None,1] )\n",
    "ys = tf.placeholder( tf.float32,[None,1] )\n",
    "\n",
    "l1 = add_layer( xs,1,10,activation_funtion=tf.nn.relu )\n",
    "prediction = add_layer( l1,10,1 )\n",
    "\n",
    "loss = tf.reduce_mean( tf.reduce_sum( tf.square( ys - prediction ),reduction_indices=[1] ) )\n",
    "train_step = tf.train.GradientDescentOptimizer( 0.1 ).minimize( loss )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run( init )\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter( x_data,y_data )\n",
    "plt.ion()\n",
    "#plt.show()\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run( train_step,feed_dict={xs:x_data,ys:y_data})\n",
    "    if i % 50 == 0:\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run( prediction,feed_dict={xs:x_data} )\n",
    "        lines = ax.plot( x_data,prediction_value,'r-',lw=5 )\n",
    "        plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 13 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.GradientDescentOptimizer()\n",
    "tf.train.MomentumOptimizer()\n",
    "tf.train.AdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 14 Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, n_layer, activation_funtion=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    layer_name = 'layer%s' % n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable( tf.random_normal( [in_size,out_size] ),name='W' )\n",
    "            tf.summary.histogram(layer_name+'/weight',Weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable( tf.zeros( [1,out_size] ) + 0.1,name='b' )\n",
    "            tf.summary.histogram(layer_name+'/biases',biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.matmul( inputs,Weights ) + biases\n",
    "        if activation_funtion is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_funtion( Wx_plus_b )\n",
    "        tf.summary.histogram(layer_name+'/outputs',outputs )\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.linspace( -1,1,300 )[:,np.newaxis]\n",
    "noise = np.random.normal( 0,0.05,x_data.shape )\n",
    "y_data = np.square( x_data ) - 0.5 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder( tf.float32,[None,1],name='x_input' )\n",
    "    ys = tf.placeholder( tf.float32,[None,1],name='y_input' )\n",
    "\n",
    "# add hidden layer\n",
    "\n",
    "l1 = add_layer( xs,1,10,n_layer=1,activation_funtion=tf.nn.relu )\n",
    "# add output layer\n",
    "prediction = add_layer( l1,10,1,n_layer=2 )\n",
    "\n",
    "# the error between prediction and real data\n",
    "with tf.name_scope( 'loss' ):\n",
    "    loss = tf.reduce_mean( tf.reduce_sum( tf.square( ys - prediction ),reduction_indices=[1] ) )\n",
    "    tf.summary.scalar( 'loss',loss )\n",
    "with tf.name_scope( 'train' ):\n",
    "    train_step = tf.train.GradientDescentOptimizer( 0.1 ).minimize( loss )\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter( \"logs/\",sess.graph )\n",
    "# important step\n",
    "sess.run( tf.global_variables_initializer() )\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run( train_step,feed_dict={xs:x_data,ys:y_data} )\n",
    "    if i % 50 == 0:\n",
    "        result = sess.run( merged,feed_dict={xs:x_data,ys:y_data} )\n",
    "        writer.add_summary( result,i )\n",
    "# Finally, using the tensorboard to draw the figure of the network\n",
    "# example: 'tensorboard --logdir='logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 16 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_funtion=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable( tf.random_normal( [in_size,out_size] ),name='W' )\n",
    "    biases = tf.Variable( tf.zeros( [1,out_size] ) + 0.1,name='b' )\n",
    "    Wx_plus_b = tf.matmul( inputs,Weights ) + biases\n",
    "    if activation_funtion is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_funtion( Wx_plus_b )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction,feed_dict={xs:v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs:v_xs , ys:v_ys})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.138\n",
      "0.6479\n",
      "0.7471\n",
      "0.7894\n",
      "0.8068\n",
      "0.821\n",
      "0.8303\n",
      "0.8415\n",
      "0.846\n",
      "0.8495\n",
      "0.855\n",
      "0.8585\n",
      "0.8565\n",
      "0.8653\n",
      "0.8628\n",
      "0.8669\n",
      "0.8689\n",
      "0.8744\n",
      "0.8754\n",
      "0.8744\n"
     ]
    }
   ],
   "source": [
    "xs = tf.placeholder( tf.float32,[None,784] )\n",
    "ys = tf.placeholder( tf.float32,[None,10] )\n",
    "\n",
    "prediction = add_layer( xs,784,10,activation_funtion=tf.nn.softmax )\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction)\n",
    "                                              ,reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run( train_step,feed_dict={xs:batch_xs , ys:batch_ys})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(mnist.test.images,mnist.test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 17 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, layer_name, keep_prod, activation_funtion=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable( tf.random_normal( [in_size,out_size] ),name='W' )\n",
    "    biases = tf.Variable( tf.zeros( [1,out_size] ) + 0.1,name='b' )\n",
    "    Wx_plus_b = tf.matmul( inputs,Weights ) + biases\n",
    "    Wx_plus_b = tf.nn.dropout(Wx_plus_b,keep_prod)\n",
    "    if activation_funtion is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_funtion( Wx_plus_b )\n",
    "    tf.summary.histogram(layer_name+'/outputs',outputs )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prod = tf.placeholder( tf.float32 )\n",
    "xs = tf.placeholder( tf.float32,[None,64] )\n",
    "ys = tf.placeholder( tf.float32,[None,10] )\n",
    "\n",
    "l1 = add_layer( xs,64,50,'l1',keep_prod,activation_funtion=tf.nn.tanh)\n",
    "prediction = add_layer( l1,50,10,'l2',keep_prod,activation_funtion=tf.nn.softmax )\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction)\n",
    "                                              ,reduction_indices=[1]))\n",
    "tf.summary.scalar('loss',cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.6).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter( \"logs/train\",sess.graph )\n",
    "test_writer = tf.summary.FileWriter( \"logs/test\",sess.graph )\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(500):\n",
    "    sess.run( train_step,feed_dict={xs:X_train , ys:y_train,keep_prod:0.5} )\n",
    "    if i % 50 == 0:\n",
    "        train_result = sess.run( merged,feed_dict={xs:X_train , ys:y_train , keep_prod:1} )\n",
    "        test_result = sess.run( merged,feed_dict={xs:X_test , ys:y_test , keep_prod:1} )\n",
    "        \n",
    "        train_writer.add_summary( train_result,i )\n",
    "        test_writer.add_summary( test_result,i )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction,feed_dict={xs:v_xs,keep_prod:1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    result = sess.run(accuracy,feed_dict={xs:v_xs , ys:v_ys})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    inital = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(inital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    inital = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(inital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    # strides [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0]=strides[4]=1\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    # strides [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets( 'MNIST_data',one_hot=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1073\n",
      "0.4297\n",
      "0.6687\n",
      "0.7587\n",
      "0.8139\n",
      "0.8429\n",
      "0.8642\n",
      "0.8804\n",
      "0.89\n",
      "0.8969\n",
      "0.9063\n",
      "0.9136\n",
      "0.9142\n",
      "0.9239\n",
      "0.9223\n",
      "0.9268\n",
      "0.9304\n",
      "0.9342\n",
      "0.9357\n",
      "0.9383\n"
     ]
    }
   ],
   "source": [
    "xs = tf.placeholder( tf.float32,[None,784] )\n",
    "ys = tf.placeholder( tf.float32,[None,10] )\n",
    "keep_prod = tf.placeholder( tf.float32 )\n",
    "x_image = tf.reshape( xs,[-1,28,28,1]) # [num,width,length,channel]\n",
    "# print(x_image.shape) # [n_sameples,28,28,1]\n",
    "\n",
    "# conv1 layer\n",
    "W_conv1 = weight_variable( [5,5,1,4] )# patch 5x5, in size 1, out size 4\n",
    "b_conv1 = bias_variable( [4] )\n",
    "h_conv1 = tf.nn.relu( conv2d( x_image,W_conv1 ) + b_conv1 )# output size is 28x28x4\n",
    "h_pool1 = max_pool_2x2( h_conv1 )                          # output size is 14x14x4\n",
    "\n",
    "# conv2 layer\n",
    "W_conv2 = weight_variable( [5,5,4,8] )# patch 5x5, in size 4, out size 8\n",
    "b_conv2 = bias_variable( [8] )\n",
    "h_conv2 = tf.nn.relu( conv2d( h_pool1,W_conv2 ) + b_conv2 )# output size is 14x14x8\n",
    "h_pool2 = max_pool_2x2( h_conv2 )                          # output size is 7x7x8\n",
    "\n",
    "# func1 layer\n",
    "W_fcl = weight_variable( [7*7*8,1024] )\n",
    "b_fc1 = bias_variable( [1024] )\n",
    "h_pool2_flat = tf.reshape( h_pool2,[-1,7*7*8] )# [n_sample,7,7,64]->>[n_sample,7*7*64]\n",
    "h_fc1 = tf.nn.relu( tf.matmul( h_pool2_flat,W_fcl ) + b_fc1 )\n",
    "h_fc1_drop = tf.nn.dropout( h_fc1,keep_prod )\n",
    "\n",
    "# func2 layer\n",
    "W_fc2 = weight_variable( [1024,10] )\n",
    "b_fc2 = bias_variable( [10] )\n",
    "prediction = tf.nn.softmax( tf.matmul( h_fc1_drop,W_fc2 ) + b_fc2 )\n",
    "\n",
    "cross_entroy = tf.reduce_mean( -tf.reduce_sum(ys * tf.log(prediction),reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entroy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run( tf.global_variables_initializer() )\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run( train_step,feed_dict={xs:batch_xs , ys:batch_ys , keep_prod:0.5} )\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy( mnist.test.images , mnist.test.labels ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensorflow 19 Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to paht:  my_net/save_net.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Save to file\n",
    "# remember to define the same dtype and shape when restore\n",
    "W = tf.Variable( [[1,2,3],[3,4,5]],dtype=tf.float32,name='weights' )\n",
    "b = tf.Variable( [[1,2,3]],dtype=tf.float32,name='biases' )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    save_path = saver.save(sess,\"my_net/save_net.ckpt\")\n",
    "    print(\"Save to paht: \",save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_net/save_net.ckpt\n",
      "weight:  [[ 1.  2.  3.]\n",
      " [ 3.  4.  5.]]\n",
      "biases:  [[ 1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "# restore variables\n",
    "# redefine the same shape and same dtype for your variable\n",
    "W = tf.Variable( np.arange(6).reshape((2,3)),dtype=tf.float32,name=\"weights\" )\n",
    "b = tf.Variable( np.arange(3).reshape((1,3)),dtype=tf.float32,name=\"biases\" )\n",
    "\n",
    "# not need init step\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore( sess,\"my_net/save_net.ckpt\" )\n",
    "    print( \"weight: \",sess.run(W) )\n",
    "    print( \"biases: \",sess.run(b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensorflow 20 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# set data\n",
    "mnist = input_data.read_data_sets( 'MNIST_data',one_hot=True )\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.6\n",
    "training_iters = 100000\n",
    "batch_size = 100\n",
    "\n",
    "n_inputs = 28\n",
    "n_steps = 28\n",
    "n_hidden_unis = 128\n",
    "n_classes = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder( tf.float32,[None,n_steps,n_inputs] )\n",
    "y = tf.placeholder( tf.float32,[None,n_classes] )\n",
    "\n",
    "# Define weights\n",
    "weights = {'in':tf.Variable( tf.random_normal([n_inputs,n_hidden_unis]) ),\n",
    "           'out':tf.Variable( tf.random_normal([n_hidden_unis,n_classes]) )}\n",
    "biases = {'in':tf.Variable( tf.constant(0.1,shape=[n_hidden_unis,]) ),\n",
    "          'out':tf.Variable( tf.constant(0.1,shape=[n_classes,]) )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(X, weights, biases):\n",
    "    # hidden layer for input to cell\n",
    "    X = tf.reshape(X,[-1,n_inputs])\n",
    "    X_in = tf.matmul(X,weights['in']) + biases['in']\n",
    "    X_in = tf.reshape(X_in,[-1,n_steps,n_hidden_unis])\n",
    "    \n",
    "    # cell\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_unis,forget_bias=1.0,state_is_tuple=True)\n",
    "    # lstm cell is divided into two parts(c_state,m_state)\n",
    "    _init_state = lstm_cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    \n",
    "    # if time is the first dim of X_in, time_major=True\n",
    "    outputs,states = tf.nn.dynamic_rnn(lstm_cell,X_in,initial_state=_init_state,time_major=False)\n",
    "    \n",
    "    # hidden layer for output as the final results\n",
    "    #results = tf.matmul(states[1],weights['out']) + biases['out']\n",
    "    # or\n",
    "    outputs = tf.unstack(tf.transpose(outputs,[1,0,2]))\n",
    "    results = tf.matmul(outputs[-1],weights['out']) + biases['out']\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.106399999484\n",
      "0.468199997544\n",
      "0.568599997759\n",
      "0.669500001669\n",
      "0.719299999475\n",
      "0.775399998426\n",
      "0.767799999714\n",
      "0.725400001407\n",
      "0.818799999952\n",
      "0.794799997807\n",
      "0.840699997544\n",
      "0.831599997282\n",
      "0.83539999783\n",
      "0.828099996448\n",
      "0.84720000267\n",
      "0.862300000787\n",
      "0.734700000286\n",
      "0.86279999733\n",
      "0.869900000095\n",
      "0.877300004363\n",
      "0.881899998784\n",
      "0.862299997211\n",
      "0.882199998498\n",
      "0.883200002909\n",
      "0.896800000072\n",
      "0.881100000143\n",
      "0.896600000858\n",
      "0.884499998093\n",
      "0.888700000644\n",
      "0.883700000048\n",
      "0.900800001621\n",
      "0.902899997234\n",
      "0.900700000525\n",
      "0.905800001621\n",
      "0.913000004888\n",
      "0.902200003266\n",
      "0.896099999547\n",
      "0.908300004005\n",
      "0.900200001597\n",
      "0.908200001121\n",
      "0.917000003457\n",
      "0.910100002289\n",
      "0.89469999969\n",
      "0.91210000217\n",
      "0.922099999785\n",
      "0.915600003004\n",
      "0.928000003099\n",
      "0.919800000191\n",
      "0.929700002074\n",
      "0.924799999595\n"
     ]
    }
   ],
   "source": [
    "pred = RNN( x,weights,biases )\n",
    "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits( labels=y , logits=pred ) )\n",
    "train_op = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal( tf.argmax(pred,1),tf.argmax(y,1) )\n",
    "accuracy = tf.reduce_mean( tf.cast(correct_pred,tf.float32) )\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape([batch_size,n_steps,n_inputs])\n",
    "        sess.run(train_op,feed_dict={x:batch_xs , y:batch_ys})\n",
    "        if step % 20 == 0:\n",
    "            acc = 0\n",
    "            for _ in range(int(10000/batch_size)):\n",
    "                test_xs,test_ys = mnist.test.next_batch(batch_size)\n",
    "                test_xs = test_xs.reshape([batch_size,n_steps,n_inputs])\n",
    "                acc = acc + sess.run(accuracy,feed_dict={x:test_xs , y:test_ys })*batch_size\n",
    "            print(acc/10000)\n",
    "            #print(sess.run(accuracy,feed_dict={x:batch_xs , y:batch_ys }))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tensorflow 20 RNN lstm regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_start = 0\n",
    "time_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bach():\n",
    "    global BATCH_START, TIME_STEPS\n",
    "    xs = np.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
